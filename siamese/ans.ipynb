{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "texts = [\n",
    "    [\"Soccer is a popular sport\", \"Basketball is a team sport\"],\n",
    "    [\"The Eiffel Tower is in Paris\", \"The Statue of Liberty is in New York\"],\n",
    "    [\"Mangoes are a tropical fruit\", \"Pineapples are also tropical fruits\"],\n",
    "    [\"Hiking in the mountains is refreshing\", \"Swimming in the ocean is relaxing\"],\n",
    "    [\"Computer science involves coding\", \"Biology focuses on living organisms\"],\n",
    "    [\"The Earth orbits the Sun\", \"The Moon orbits the Earth\"],\n",
    "    [\"Cats have whiskers\", \"Snakes are limbless reptiles\"],\n",
    "    [\"Writing code can be challenging\", \"Reading books is a leisurely activity\"],\n",
    "    [\"Chemistry deals with chemical reactions\", \"Physics studies the laws of nature\"],\n",
    "    [\"Mount Everest is the world's tallest peak\", \"K2 is also a tall mountain\"],\n",
    "    [\"Artists create visual masterpieces\", \"Musicians compose melodious tunes\"],\n",
    "    [\"Summer is hot and sunny\", \"Winter is cold and snowy\"],\n",
    "    [\"Insects have six legs\", \"Spiders are arachnids with eight legs\"],\n",
    "    [\"London is the capital of England\", \"Tokyo is the capital of Japan\"],\n",
    "    [\"Learning a new language is a valuable skill\", \"Cooking delicious food is an art\"],\n",
    "    [\"Elephants are large mammals\", \"Kangaroos are marsupials\"],\n",
    "    [\"Rivers flow downstream to the sea\", \"Waterfalls are breathtaking natural wonders\"],\n",
    "    [\"Astronomy explores celestial objects\", \"Geology studies the Earth's structure\"],\n",
    "    [\"Singing requires vocal talent\", \"Dancing showcases body movements\"],\n",
    "    [\"Gardening is a peaceful hobby\", \"Extreme sports offer adrenaline rushes\"]\n",
    "]\n",
    "labels = [1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "max_seq_length = max(len(seq) for seq in sequences)\n",
    "sequences = pad_sequences(sequences, maxlen=max_seq_length)\n",
    "\n",
    "input_pairs = [(sequences[i], sequences[j]) for i in range(len(texts)) for j in range(len(texts)) if i != j]\n",
    "labels = np.array(labels * (len(texts) - 1))  \n",
    "\n",
    "indices = np.arange(len(input_pairs))\n",
    "np.random.shuffle(indices)\n",
    "input_pairs = np.array(input_pairs)[indices]\n",
    "labels = labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "input_a = Input(shape=(max_seq_length,))\n",
    "input_b = Input(shape=(max_seq_length,))\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=128)\n",
    "\n",
    "encoded_a = embedding_layer(input_a)\n",
    "encoded_b = embedding_layer(input_b)\n",
    "\n",
    "def cosine_similarity(vectors):\n",
    "    x, y = vectors\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return K.sum(x * y, axis=-1)\n",
    "\n",
    "similarity_layer = Lambda(cosine_similarity, output_shape=(1,))([encoded_a, encoded_b])\n",
    "\n",
    "siamese_model = Model(inputs=[input_a, input_b], outputs=similarity_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "siamese_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 2ms/step - loss: 0.5102 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.5026\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.4974\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.5079\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.5132\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.5132\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.5211\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.5053\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.4921\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.4842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x184d17726e0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "siamese_model.fit([input_pairs[:, 0], input_pairs[:, 1]], labels, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_definition = \"Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks requiring human intelligence. These tasks include learning from experience (machine learning), understanding natural language, recognizing patterns, and solving problems. AI can be broadly categorized into Narrow AI (specialized for specific tasks) and General AI (possessing human-like cognitive abilities across a range of tasks).\"\n",
    "\n",
    "sl_definition = \"Supervised Learning is a type of machine learning where the algorithm is trained on a labeled dataset. In supervised learning, the algorithm is provided with input-output pairs, where the input data is labeled with the corresponding correct output. The algorithm learns to map the input data to the correct output by generalizing from the labeled examples. The goal is to make predictions or classifications on new, unseen data. Examples of supervised learning tasks include image classification, speech recognition, and regression analysis.\"\n",
    "\n",
    "ul_definition = \"Unsupervised Learning is a type of machine learning where the algorithm is given input data without explicit instructions on what to do with it. The system tries to learn the patterns and structure from the data without labeled outputs. The goal is often to discover hidden patterns, relationships, or groupings within the data. Clustering and dimensionality reduction are common tasks in unsupervised learning. Examples include clustering similar documents, identifying topics in a collection of articles, and reducing the dimensionality of data for visualization.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_definition_updated = \"Artificial Intelligence (AI) encompasses the development of computer systems capable of emulating human intelligence. This includes tasks like learning from experience (machine learning), comprehending natural language, identifying patterns, and solving problems. AI is broadly categorized into Narrow AI (specialized tasks) and General AI (human-like cognitive abilities).\"\n",
    "\n",
    "sl_definition_updated = \"In Supervised Learning, algorithms are trained on labeled datasets. Input-output pairs are provided, where input data is labeled with correct outputs. Algorithms learn to generalize from these labeled examples, making predictions or classifications on new, unseen data. Examples include image classification, speech recognition, and regression analysis.\"\n",
    "\n",
    "ul_definition_updated = \"Unsupervised Learning involves algorithms processing unlabeled data without explicit guidance. The goal is to discover patterns or relationships within the data. Common tasks include clustering similar data points and reducing dimensionality for visualization. Examples include grouping documents, identifying topics, and exploring data structure.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "Similarity Score: 1.0\n",
      "The texts are similar.\n"
     ]
    }
   ],
   "source": [
    "# Example new text pair\n",
    "new_text_pair = [ai_definition, ai_definition_updated]\n",
    "\n",
    "\n",
    "# Preprocess the new text pair (tokenization and padding)\n",
    "new_sequences = tokenizer.texts_to_sequences(new_text_pair)\n",
    "new_sequences = pad_sequences(new_sequences, maxlen=max_seq_length)\n",
    "\n",
    "# Make predictions\n",
    "similarity_score = siamese_model.predict([new_sequences[0], new_sequences[1]])\n",
    "\n",
    "# Print the similarity score\n",
    "print(f\"Similarity Score: {similarity_score[0]}\")\n",
    "\n",
    "# You can define a threshold to decide if the texts are similar or dissimilar\n",
    "threshold = 0.5  # Adjust this threshold as needed\n",
    "if similarity_score[0] > threshold:\n",
    "    print(\"The texts are similar.\")\n",
    "else:\n",
    "    print(\"The texts are dissimilar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pairs = [\n",
    "    (\"I love cats\", \"I adore felines\"),\n",
    "    (\"Dogs are loyal animals\", \"Cats are independent creatures\"),\n",
    "    (\"Apples are red\", \"Bananas are yellow\"),\n",
    "    (\"Pizza is delicious\", \"Ice cream is sweet\"),\n",
    "    (\"Python is a programming language\", \"Java is also a programming language\"),\n",
    "    (\"The sun rises in the east\", \"The moon shines at night\"),\n",
    "]\n",
    "\n",
    "\n",
    "validation_labels = [1, 0, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    }
   ],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences([pair[0] for pair in validation_pairs])\n",
    "validation_sequences = pad_sequences(validation_sequences, maxlen=max_seq_length)\n",
    "validation_sequences_2 = tokenizer.texts_to_sequences([pair[1] for pair in validation_pairs])\n",
    "validation_sequences_2 = pad_sequences(validation_sequences_2, maxlen=max_seq_length)\n",
    "\n",
    "similarity_scores = siamese_model.predict([validation_sequences, validation_sequences_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "\n",
    "for i in range(len(validation_labels)):\n",
    "    if validation_labels[i] == 1:\n",
    "        if similarity_scores[i][0] >= threshold:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "    else:\n",
    "        if similarity_scores[i][0] >= threshold:\n",
    "            false_positives += 1\n",
    "        else:\n",
    "            true_negatives += 1\n",
    "\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
