{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-10T17:13:54.040164Z","iopub.execute_input":"2023-10-10T17:13:54.040603Z","iopub.status.idle":"2023-10-10T17:13:54.050565Z","shell.execute_reply.started":"2023-10-10T17:13:54.040572Z","shell.execute_reply":"2023-10-10T17:13:54.048718Z"},"trusted":true},"execution_count":515,"outputs":[{"name":"stdout","text":"/kaggle/input/semantic-similarity/train - train.csv\n/kaggle/input/semantic-similarity/evaluation - evaluation.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertModel\nimport torch\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:54.053002Z","iopub.execute_input":"2023-10-10T17:13:54.054064Z","iopub.status.idle":"2023-10-10T17:13:54.063395Z","shell.execute_reply.started":"2023-10-10T17:13:54.054030Z","shell.execute_reply":"2023-10-10T17:13:54.062625Z"},"trusted":true},"execution_count":516,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained DistillBERT model and tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:54.065509Z","iopub.execute_input":"2023-10-10T17:13:54.066842Z","iopub.status.idle":"2023-10-10T17:13:54.966746Z","shell.execute_reply.started":"2023-10-10T17:13:54.066790Z","shell.execute_reply":"2023-10-10T17:13:54.965687Z"},"trusted":true},"execution_count":517,"outputs":[]},{"cell_type":"code","source":"ideal=\"Artificial Intelligence (AI) refers to computer systems designed to perform tasks that typically require human intelligence. It encompasses various technologies like machine learning and deep learning, enabling machines to analyze data, recognize patterns, and make decisions. AI systems can excel in tasks such as image and speech recognition, natural language processing, and problem-solving. As an interdisciplinary field, AI aims to create machines capable of learning and adapting, advancing technology's ability to automate processes, enhance efficiency, and address complex challenges across industries, from healthcare and finance to transportation and beyond, heralding a transformative era in the way we interact with and utilize technology.\"","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:54.970832Z","iopub.execute_input":"2023-10-10T17:13:54.971351Z","iopub.status.idle":"2023-10-10T17:13:54.978044Z","shell.execute_reply.started":"2023-10-10T17:13:54.971312Z","shell.execute_reply":"2023-10-10T17:13:54.976568Z"},"trusted":true},"execution_count":518,"outputs":[]},{"cell_type":"code","source":"wrong=\"Birds, a diverse class of warm-blooded vertebrates, encompass a vast array of species adapted to environments worldwide. Renowned for their ability to fly, birds exhibit remarkable diversity in size, color, and behavior. From the majestic eagles soaring in the sky to the tiny hummingbirds darting among flowers, they play crucial ecological roles as pollinators, seed dispersers, and insect controllers. Birds, with their unique songs and intricate plumage, captivate humans, inspiring art, folklore, and scientific inquiry. Their migratory journeys across continents showcase astonishing feats of navigation. Birds serve as vital indicators of environmental health, emphasizing the interconnectedness of ecosystems.\"","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:54.980268Z","iopub.execute_input":"2023-10-10T17:13:54.980931Z","iopub.status.idle":"2023-10-10T17:13:54.995954Z","shell.execute_reply.started":"2023-10-10T17:13:54.980894Z","shell.execute_reply":"2023-10-10T17:13:54.994855Z"},"trusted":true},"execution_count":519,"outputs":[]},{"cell_type":"code","source":"student=\"Artificial Intelligence (AI) is a branch of computer science that empowers machines to simulate human intelligence. Utilizing algorithms, AI enables systems to learn from data, recognize patterns, and make decisions, mimicking cognitive functions. Applications span from natural language processing and image recognition to autonomous vehicles. AI is a transformative force, impacting industries, improving efficiency, and raising ethical considerations regarding privacy and bias. As technology evolves, AI continues to shape our daily lives, advancing fields like healthcare, finance, and robotics, while fostering a future where machines seamlessly interact with and augment human capabilities.\"","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:54.997356Z","iopub.execute_input":"2023-10-10T17:13:54.997688Z","iopub.status.idle":"2023-10-10T17:13:55.011492Z","shell.execute_reply.started":"2023-10-10T17:13:54.997661Z","shell.execute_reply":"2023-10-10T17:13:55.010237Z"},"trusted":true},"execution_count":520,"outputs":[]},{"cell_type":"code","source":"# Tokenize input text\ntokens1 = tokenizer(ideal, return_tensors='pt')\ntokens2 = tokenizer(student, return_tensors='pt')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:55.014164Z","iopub.execute_input":"2023-10-10T17:13:55.015061Z","iopub.status.idle":"2023-10-10T17:13:55.039237Z","shell.execute_reply.started":"2023-10-10T17:13:55.014992Z","shell.execute_reply":"2023-10-10T17:13:55.037865Z"},"trusted":true},"execution_count":521,"outputs":[]},{"cell_type":"code","source":"# Generate embeddings\nwith torch.no_grad():\n    embeddings1 = model(**tokens1).last_hidden_state.mean(dim=1)\n    embeddings2 = model(**tokens2).last_hidden_state.mean(dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:55.040514Z","iopub.execute_input":"2023-10-10T17:13:55.040811Z","iopub.status.idle":"2023-10-10T17:13:55.305623Z","shell.execute_reply.started":"2023-10-10T17:13:55.040787Z","shell.execute_reply":"2023-10-10T17:13:55.304430Z"},"trusted":true},"execution_count":522,"outputs":[]},{"cell_type":"code","source":"# Generate embeddings\nwith torch.no_grad():\n    embeddings1 = model(**tokens1).last_hidden_state.mean(dim=1)\n    embeddings2 = model(**tokens2).last_hidden_state.mean(dim=1)\n\n# Calculate cosine similarity\nsimilarity = cosine_similarity(embeddings1, embeddings2)\n# print(f\"Similarity: {similarity[0][0]}\")\nif similarity[0][0]>0.95:\n    print(\"Two corpus are similar\")\nelse:\n    print(\"The corpus are not similar\")","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:55.308581Z","iopub.execute_input":"2023-10-10T17:13:55.309310Z","iopub.status.idle":"2023-10-10T17:13:55.569532Z","shell.execute_reply.started":"2023-10-10T17:13:55.309280Z","shell.execute_reply":"2023-10-10T17:13:55.567964Z"},"trusted":true},"execution_count":523,"outputs":[{"name":"stdout","text":"Two corpus are similar\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize input text\ntokens1 = tokenizer(ideal, return_tensors='pt')\ntokens2 = tokenizer(wrong, return_tensors='pt')\n\n# Generate embeddings\nwith torch.no_grad():\n    embeddings1 = model(**tokens1).last_hidden_state.mean(dim=1)\n    embeddings2 = model(**tokens2).last_hidden_state.mean(dim=1)\n\n\n# Generate embeddings\nwith torch.no_grad():\n    embeddings1 = model(**tokens1).last_hidden_state.mean(dim=1)\n    embeddings2 = model(**tokens2).last_hidden_state.mean(dim=1)\n\n# Calculate cosine similarity\nsimilarity = cosine_similarity(embeddings1, embeddings2)\nif similarity[0][0]>0.90:\n    print(\"Two corpus are similar\")\nelse:\n    print(\"The corpus are not similar\")","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:55.571287Z","iopub.execute_input":"2023-10-10T17:13:55.571748Z","iopub.status.idle":"2023-10-10T17:13:56.096592Z","shell.execute_reply.started":"2023-10-10T17:13:55.571720Z","shell.execute_reply":"2023-10-10T17:13:56.095450Z"},"trusted":true},"execution_count":524,"outputs":[{"name":"stdout","text":"The corpus are not similar\n","output_type":"stream"}]},{"cell_type":"code","source":"mid=\"Machine Learning (ML) is a subset of artificial intelligence that focuses on enabling computers to learn and improve from experience without being explicitly programmed.\"","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:56.098214Z","iopub.execute_input":"2023-10-10T17:13:56.099613Z","iopub.status.idle":"2023-10-10T17:13:56.104658Z","shell.execute_reply.started":"2023-10-10T17:13:56.099546Z","shell.execute_reply":"2023-10-10T17:13:56.103524Z"},"trusted":true},"execution_count":525,"outputs":[]},{"cell_type":"code","source":"# Tokenize input text\ntokens1 = tokenizer(ideal, return_tensors='pt')\ntokens2 = tokenizer(mid, return_tensors='pt')\n\n# Generate embeddings\nwith torch.no_grad():\n    embeddings1 = model(**tokens1).last_hidden_state.mean(dim=1)\n    embeddings2 = model(**tokens2).last_hidden_state.mean(dim=1)\n\n\n# Generate embeddings\nwith torch.no_grad():\n    embeddings1 = model(**tokens1).last_hidden_state.mean(dim=1)\n    embeddings2 = model(**tokens2).last_hidden_state.mean(dim=1)\n\n# Calculate cosine similarity\nsimilarity = cosine_similarity(embeddings1, embeddings2)\n\nif similarity[0][0]>0.95:\n    print(\"Two corpus are similar\")\nelif 0.95>similarity[0][0]>0.90:\n    print(\"Middle similarity\")\nelse:\n    print(\"The corpus are not similar\")","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:56.106565Z","iopub.execute_input":"2023-10-10T17:13:56.106982Z","iopub.status.idle":"2023-10-10T17:13:56.453832Z","shell.execute_reply.started":"2023-10-10T17:13:56.106943Z","shell.execute_reply":"2023-10-10T17:13:56.452788Z"},"trusted":true},"execution_count":526,"outputs":[{"name":"stdout","text":"Middle similarity\n","output_type":"stream"}]},{"cell_type":"markdown","source":"*take up data*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:56.455800Z","iopub.execute_input":"2023-10-10T17:13:56.456213Z","iopub.status.idle":"2023-10-10T17:13:56.461774Z","shell.execute_reply.started":"2023-10-10T17:13:56.456172Z","shell.execute_reply":"2023-10-10T17:13:56.460652Z"},"trusted":true},"execution_count":527,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/semantic-similarity/train - train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:56.463638Z","iopub.execute_input":"2023-10-10T17:13:56.464054Z","iopub.status.idle":"2023-10-10T17:13:56.487479Z","shell.execute_reply.started":"2023-10-10T17:13:56.464016Z","shell.execute_reply":"2023-10-10T17:13:56.486269Z"},"trusted":true},"execution_count":528,"outputs":[]},{"cell_type":"code","source":"df.head","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:56.490251Z","iopub.execute_input":"2023-10-10T17:13:56.490590Z","iopub.status.idle":"2023-10-10T17:13:56.501632Z","shell.execute_reply.started":"2023-10-10T17:13:56.490564Z","shell.execute_reply":"2023-10-10T17:13:56.500331Z"},"trusted":true},"execution_count":529,"outputs":[{"execution_count":529,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.head of       Unnamed: 0                                               text  \\\n0              0                  can not share audio via bluetooth   \n1              1                      Google sign-in does not work!   \n2              2     the best platform to communicate in a pandemic   \n3              3                  it will not open on my telephone!   \n4              4  this app is very expensive to learn study onli...   \n...          ...                                                ...   \n4117        4117  it does not allow me to change the language of...   \n4118        4118                 the best app in populate cyclosis!   \n4119        4119                    getting too many notifications.   \n4120        4120  why can not you hear me without headphones dur...   \n4121        4121       there is not touchup option available as yet   \n\n                                     reason  label  \n0             good for on-line presentation      0  \n1                         hard to use video      0  \n2                    good for communication      1  \n3                       app is bad for work      0  \n4       app is expensive for online classes      1  \n...                                     ...    ...  \n4117  want subtitles translation in english      1  \n4118          want to enter electronic_mail      0  \n4119         getting too many notifications      1  \n4120  want to hear audio without headphones      1  \n4121         want to mirror audio and video      0  \n\n[4122 rows x 4 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"tokens1 = tokenizer(df['text'].tolist(), return_tensors='pt', padding=True, truncation=True)\ntokens2 = tokenizer(df['reason'].tolist(), return_tensors='pt', padding=True, truncation=True)\n\n# Convert labels to tensor\nlabels = torch.tensor(df['label'].values).view(-1, 1)  # No need for float() as labels are already 0 or 1\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:56.502963Z","iopub.execute_input":"2023-10-10T17:13:56.503668Z","iopub.status.idle":"2023-10-10T17:13:58.814139Z","shell.execute_reply.started":"2023-10-10T17:13:56.503637Z","shell.execute_reply":"2023-10-10T17:13:58.812799Z"},"trusted":true},"execution_count":530,"outputs":[]},{"cell_type":"code","source":"class SimilarityModel(nn.Module):\n    def __init__(self, hidden_size=768):\n        super(SimilarityModel, self).__init__()\n        self.distilbert = model\n        self.fc = nn.Linear(2 * hidden_size, 1)  # Adjust input size based on your model\n\n    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n        outputs1 = self.distilbert(input_ids=input_ids1, attention_mask=attention_mask1)\n        outputs2 = self.distilbert(input_ids=input_ids2, attention_mask=attention_mask2)\n        last_hidden_state1 = outputs1.last_hidden_state.mean(dim=1)\n        last_hidden_state2 = outputs2.last_hidden_state.mean(dim=1)\n        concatenated = torch.cat((last_hidden_state1, last_hidden_state2), dim=1)\n        output = self.fc(concatenated)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:58.815695Z","iopub.execute_input":"2023-10-10T17:13:58.816880Z","iopub.status.idle":"2023-10-10T17:13:58.827070Z","shell.execute_reply.started":"2023-10-10T17:13:58.816823Z","shell.execute_reply":"2023-10-10T17:13:58.825736Z"},"trusted":true},"execution_count":531,"outputs":[]},{"cell_type":"code","source":"model = SimilarityModel(hidden_size=768)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = Adam(model.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:58.828363Z","iopub.execute_input":"2023-10-10T17:13:58.828683Z","iopub.status.idle":"2023-10-10T17:13:58.843958Z","shell.execute_reply.started":"2023-10-10T17:13:58.828659Z","shell.execute_reply":"2023-10-10T17:13:58.842580Z"},"trusted":true},"execution_count":532,"outputs":[]},{"cell_type":"code","source":"dataset = TensorDataset(tokens1['input_ids'], tokens1['attention_mask'], tokens2['input_ids'], tokens2['attention_mask'], labels)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        optimizer.zero_grad()\n        \n        outputs = model(input_ids1=batch[0], attention_mask1=batch[1], input_ids2=batch[2], attention_mask2=batch[3])\n        loss = criterion(outputs, batch[4].float())  # Convert labels to float\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:13:58.845652Z","iopub.execute_input":"2023-10-10T17:13:58.846119Z","iopub.status.idle":"2023-10-10T17:14:06.826073Z","shell.execute_reply.started":"2023-10-10T17:13:58.846086Z","shell.execute_reply":"2023-10-10T17:14:06.824005Z"},"trusted":true},"execution_count":533,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[533], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(input_ids1\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m], attention_mask1\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m1\u001b[39m], input_ids2\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m], attention_mask2\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat())  \u001b[38;5;66;03m# Convert labels to float\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def get_similarity_score(model, tokenizer, text1, text2):\n    # Tokenize input text\n    tokens1 = tokenizer(text1, return_tensors='pt', padding=True, truncation=True)\n    tokens2 = tokenizer(text2, return_tensors='pt', padding=True, truncation=True)\n\n    # Model prediction\n    with torch.no_grad():\n        output1 = model(**tokens1)\n        output2 = model(**tokens2)\n\n        # Assuming the last hidden states are used for classification\n        last_hidden_state1 = output1.last_hidden_state.mean(dim=1)\n        last_hidden_state2 = output2.last_hidden_state.mean(dim=1)\n\n        # Concatenate the embeddings\n        concatenated = torch.cat((last_hidden_state1, last_hidden_state2), dim=1)\n\n        # Pass through the linear layer\n        similarity_score = torch.sigmoid(model.fc(concatenated)).item()\n\n    return similarity_score\n\n# Example usage\ntext1 = \"This is the first statement.\"\ntext2 = \"This is a similar statement.\"\n\nsimilarity_score = get_similarity_score(model, tokenizer, text1, text2)\nprint(f\"Similarity Score: {similarity_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:14:06.827121Z","iopub.status.idle":"2023-10-10T17:14:06.827511Z","shell.execute_reply.started":"2023-10-10T17:14:06.827320Z","shell.execute_reply":"2023-10-10T17:14:06.827336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ideal=\"Artificial Intelligence (AI) refers to computer systems designed to perform tasks that typically require human intelligence. It encompasses various technologies like machine learning and deep learning, enabling machines to analyze data, recognize patterns, and make decisions. AI systems can excel in tasks such as image and speech recognition, natural language processing, and problem-solving. As an interdisciplinary field, AI aims to create machines capable of learning and adapting, advancing technology's ability to automate processes, enhance efficiency, and address complex challenges across industries, from healthcare and finance to transportation and beyond, heralding a transformative era in the way we interact with and utilize technology.\"\n\nans=\"Birds, a diverse class of warm-blooded vertebrates, encompass a vast array of species adapted to environments worldwide. Renowned for their ability to fly, birds exhibit remarkable diversity in size, color, and behavior. From the majestic eagles soaring in the sky to the tiny hummingbirds darting among flowers, they play crucial ecological roles as pollinators, seed dispersers, and insect controllers. Birds, with their unique songs and intricate plumage, captivate humans, inspiring art, folklore, and scientific inquiry. Their migratory journeys across continents showcase astonishing feats of navigation. Birds serve as vital indicators of environmental health, emphasizing the interconnectedness of ecosystems.\"\n\n# Tokenize input text\ntokens1 = tokenizer(ideal, return_tensors='pt')\ntokens2 = tokenizer(ans, return_tensors='pt')\n\n# Generate embeddings\nwith torch.no_grad():\n    embeddings1 = model(**tokens1).last_hidden_state.mean(dim=1)\n    embeddings2 = model(**tokens2).last_hidden_state.mean(dim=1)\n\n# Calculate cosine similarity\nsimilarity = cosine_similarity(embeddings1, embeddings2)\nprint(f\"Similarity: {similarity[0][0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-10T17:14:06.828739Z","iopub.status.idle":"2023-10-10T17:14:06.829178Z","shell.execute_reply.started":"2023-10-10T17:14:06.828996Z","shell.execute_reply":"2023-10-10T17:14:06.829014Z"},"trusted":true},"execution_count":null,"outputs":[]}]}